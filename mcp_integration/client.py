import json
import asyncio
import os
import random
import time
from typing import Optional
from contextlib import AsyncExitStack

from openai import OpenAI
from dotenv import load_dotenv

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

load_dotenv("dotenv.env")

class EnhancedMCPClient:
    def __init__(self):
        self.session: Optional[ClientSession] = None
        self.exit_stack = AsyncExitStack()
        
        # åçˆ¬è™«ä¿æŠ¤è®¾ç½®
        self.last_tool_call_time = 0
        self.min_call_interval = 3  # æœ€å°è°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰
        self.max_call_interval = 8  # æœ€å¤§è°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰
        
        # Initialize OpenAI client with environment variables
        api_key = os.getenv("OPENAI_API_KEY")
        base_url = os.getenv("OPENAI_BASE_URL")
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable must be set")
        
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url
        )
        
    async def connect_to_server(self):
        server_params = StdioServerParameters(
            command='python',
            args=['-m', 'mcp_integration.server'], # ä¿®æ­£äº†å¯åŠ¨å‘½ä»¤
            env=None
        )

        # ä½¿ç”¨ä¸ client.py ç›¸åŒçš„æ–¹å¼
        self.stdio_transport = await self.exit_stack.enter_async_context(
            stdio_client(server_params))
        
        # ç¡®ä¿æ­£ç¡®è§£åŒ…è¿”å›å€¼
        if hasattr(self.stdio_transport, '__iter__') and not isinstance(self.stdio_transport, str):
            try:
                stdio, write = self.stdio_transport
            except ValueError as e:
                print(f"è§£åŒ…stdio_transportå¤±è´¥: {e}")
                print(f"stdio_transportç±»å‹: {type(self.stdio_transport)}")
                print(f"stdio_transportå†…å®¹: {self.stdio_transport}")
                raise
        else:
            raise ValueError(f"æ„å¤–çš„stdio_transportç±»å‹: {type(self.stdio_transport)}")
            
        self.session = await self.exit_stack.enter_async_context(
            ClientSession(stdio, write))

        await self.session.initialize()
        print("âœ… å·²è¿æ¥åˆ°Googleæœç´¢MCPæœåŠ¡å™¨ / Connected to Google Search MCP Server")
        
    async def anti_bot_protection(self):
        """åçˆ¬è™«ä¿æŠ¤ï¼šåœ¨å·¥å…·è°ƒç”¨ä¹‹é—´æ·»åŠ éšæœºå»¶è¿Ÿ"""
        current_time = time.time()
        time_since_last_call = current_time - self.last_tool_call_time
        
        if time_since_last_call < self.min_call_interval:
            # å¦‚æœè·ç¦»ä¸Šæ¬¡è°ƒç”¨æ—¶é—´å¤ªçŸ­ï¼Œç­‰å¾…éšæœºæ—¶é—´
            wait_time = random.uniform(self.min_call_interval, self.max_call_interval)
            print(f"ğŸ›¡ï¸ åçˆ¬è™«ä¿æŠ¤ï¼šç­‰å¾… {wait_time:.1f} ç§’... / Anti-bot protection: Waiting {wait_time:.1f} seconds...")
            await asyncio.sleep(wait_time)
        
        self.last_tool_call_time = time.time()
        
    async def process_query(self, query: str) -> str:
        # å¢å¼ºçš„ç³»ç»Ÿæç¤ºï¼Œæ˜ç¡®å…è®¸ä½¿ç”¨æœç´¢å·¥å…·
        system_prompt = (
            "You are an AI assistant with access to a real-time web search tool. "
            "When a user asks a question that may require up-to-date, current, or web-based information, "
            "you MUST use the google-search tool to get accurate results. "
            "The google-search tool requires a 'query' parameter, which must contain the user's search keywords or question. "
            "Always place the user's full question or main keywords in the 'query' field when calling the tool. "
            "Do not answer questions about current events, news, or potentially outdated topics using only your training dataâ€”"
            "always use the google-search tool first. "
            "After searching, provide a comprehensive answer based on the search results. "
            "For date-related or time-sensitive questions, use the search tool to get the latest information and avoid giving outdated dates or facts."
        )
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": query}
        ]

        # è·å–æ‰€æœ‰ mcp æœåŠ¡å™¨ å·¥å…·åˆ—è¡¨ä¿¡æ¯
        response = await self.session.list_tools()
        print(f"ğŸ”§ å¯ç”¨å·¥å…·: {[tool.name for tool in response.tools]} / Available tools: {[tool.name for tool in response.tools]}")
        
        # ç”Ÿæˆ function call çš„æè¿°ä¿¡æ¯
        available_tools = [{
            "type": "function",
            "function": {
                "name": tool.name,
                "description": tool.description,
                "input_schema": tool.inputSchema
            }
        } for tool in response.tools]

        # è¯·æ±‚ OpenAIï¼Œfunction call çš„æè¿°ä¿¡æ¯é€šè¿‡ tools å‚æ•°ä¼ å…¥
        response = self.client.chat.completions.create(
            model=os.getenv("OPENAI_MODEL"),
            messages=messages,
            tools=available_tools,
            tool_choice="auto"  # è®©æ¨¡å‹è‡ªåŠ¨å†³å®šæ˜¯å¦ä½¿ç”¨å·¥å…·
        )

        # å¤„ç†è¿”å›çš„å†…å®¹
        content = response.choices[0]
        if content.finish_reason == "tool_calls":
            # å¦‚æœéœ€è¦ä½¿ç”¨å·¥å…·ï¼Œå°±è§£æå·¥å…·
            tool_call = content.message.tool_calls[0]
            tool_name = tool_call.function.name
            tool_args = json.loads(tool_call.function.arguments)

            # åçˆ¬è™«ä¿æŠ¤
            # await self.anti_bot_protection()

            # æ‰§è¡Œå·¥å…·
            print(f"\nğŸ” æ­£åœ¨æ‰§è¡Œå·¥å…·: {tool_name} / Executing tool: {tool_name}")
            print(f"ğŸ“ Parameters: {json.dumps(tool_args, ensure_ascii=False, indent=2)}")
            
            try:
                # æ·»åŠ å·¥å…·è°ƒç”¨è¶…æ—¶ä¿æŠ¤
                result = await asyncio.wait_for(
                    self.session.call_tool(tool_name, tool_args),
                    timeout=300.0  # 300ç§’è¶…æ—¶
                )
            except asyncio.TimeoutError:
                print("â° å·¥å…·è°ƒç”¨è¶…æ—¶ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯ / Tool call timeout, returning error message")
                return "æŠ±æ­‰ï¼Œæœç´¢è¯·æ±‚è¶…æ—¶ã€‚è¿™å¯èƒ½æ˜¯ç”±äºç½‘ç»œé—®é¢˜æˆ–Googleçš„åçˆ¬è™«æœºåˆ¶ã€‚è¯·ç¨åé‡è¯•ã€‚"
            except Exception as e:
                print(f"âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {e} / Tool call failed: {e}")
                return f"æœç´¢å¤±è´¥: {str(e)}"
			
            # å°† OpenAI è¿”å›çš„è°ƒç”¨å“ªä¸ªå·¥å…·æ•°æ®å’Œå·¥å…·æ‰§è¡Œå®Œæˆåçš„æ•°æ®éƒ½å­˜å…¥messagesä¸­
            messages.append(content.message.model_dump())
            
            # æ­£ç¡®å¤„ç† call_tool çš„è¿”å›å€¼
            if hasattr(result, 'content') and result.content:
                # è·å–ç¬¬ä¸€ä¸ªå†…å®¹é¡¹
                first_content = result.content[0]
                if hasattr(first_content, 'text'):
                    # å¦‚æœæ˜¯ TextContentï¼Œç›´æ¥è·å– text å­—æ®µ
                    tool_content = first_content.text
                else:
                    # å…¶ä»–ç±»å‹çš„å†…å®¹ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                    tool_content = str(first_content)
            else:
                # å¦‚æœæ²¡æœ‰ contentï¼Œç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                tool_content = str(result)
            
            print(f"ğŸ“Š å·¥å…·æ‰§è¡Œç»“æœé•¿åº¦: {len(tool_content)} å­—ç¬¦ / Tool execution result length: {len(tool_content)} characters")
            
            messages.append({
                "role": "tool",
                "content": tool_content,
                "tool_call_id": tool_call.id,
            })

            # å†æ¬¡åçˆ¬è™«ä¿æŠ¤ï¼Œåœ¨ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆå‰ç­‰å¾…
            # await self.anti_bot_protection()

            # å°†ä¸Šé¢çš„ç»“æœå†è¿”å›ç»™ OpenAI ç”¨äºç”Ÿæˆæœ€ç»ˆçš„ç»“æœ
            print("ğŸ¤– æ­£åœ¨ç”Ÿæˆæœ€ç»ˆå›ç­”... / Generating final answer...")
            response = self.client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL"),
                messages=messages,
                max_tokens=20000,
            )
            return response.choices[0].message.content

        return content.message.content
        
    async def chat_loop(self):
        print("\nğŸš€ Googleæœç´¢å¢å¼ºç‰ˆMCPå®¢æˆ·ç«¯å·²å¯åŠ¨! / Google Search Enhanced MCP Client Started!")
        print("ğŸ’¡ ç°åœ¨ä½ å¯ä»¥è¯¢é—®ä»»ä½•éœ€è¦å®æ—¶ä¿¡æ¯çš„é—®é¢˜ / You can now ask any questions that require real-time information")
        print("ğŸ” ç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨Googleæœç´¢æ¥è·å–æœ€æ–°ä¿¡æ¯ / The system will automatically use Google Search to get the latest information")
        print("ğŸ›¡ï¸ å·²å¯ç”¨åçˆ¬è™«ä¿æŠ¤æœºåˆ¶ / Anti-bot protection mechanism enabled")
        print("â“ è¾“å…¥ 'quit' é€€å‡ºç¨‹åº / Type 'quit' to exit the program\n")
        
        while True:
            try:
                query = input("\nğŸ¤” è¯·è¾“å…¥ä½ çš„é—®é¢˜ / Please enter your question: ").strip()

                if query.lower() == 'quit':
                    break

                if not query:
                    continue

                print("\nâ³ æ­£åœ¨å¤„ç†ä½ çš„é—®é¢˜... / Processing your question...")
                response = await self.process_query(query)
                print(f"\nğŸ¤– AIå›ç­” / AI Answer:\n{response}")

            except Exception as e:
                import traceback
                print(f"\nâŒ å‘ç”Ÿé”™è¯¯ / Error occurred: {e}")
                traceback.print_exc()

    async def cleanup(self):
        """Clean up resources"""
        await self.exit_stack.aclose()

async def main():
    client = EnhancedMCPClient()
    try:
        await client.connect_to_server()
        await client.chat_loop()
    finally:
        await client.cleanup()

if __name__ == "__main__":
    asyncio.run(main())